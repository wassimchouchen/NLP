{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wassimchouchen/Natural-Language-Processing/blob/main/FALCON_7B_(text_generation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required Libraries"
      ],
      "metadata": {
        "id": "zzDQuCnTijqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate einops"
      ],
      "metadata": {
        "id": "ypeXsY_pjtGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the libraries\n",
        "\n",
        "and\n",
        "\n",
        "Load the Tokenizer"
      ],
      "metadata": {
        "id": "LgAh38GQinhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model = \"tiiuae/falcon-7b-instruct\" #tiiuae/falcon-40b-instruct\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)"
      ],
      "metadata": {
        "id": "WYfeJgD_j96r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Model Pipeline using Hugging Face Transformers Pipeline"
      ],
      "metadata": {
        "id": "I5ooP991iqed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "N6KzsIXEkAfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Inference using the pipeline that was built above"
      ],
      "metadata": {
        "id": "gvrJbV6niug8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"when i provide you texts could you analyse them and tell me if they contain aggresivity or joy or family tone?, they are in french!\""
      ],
      "metadata": {
        "id": "ohRirviNksC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sequences = pipeline(\n",
        "    prompt,\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSpHVwQDnecx",
        "outputId": "358c0306-8ba4-4a3f-cb83-0d580a308f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the Final Result"
      ],
      "metadata": {
        "id": "Gz8wzWdOizUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_lhX8Wei_xB",
        "outputId": "7d1719a5-2994-42d7-9a4d-6208fc960fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: when i provide you texts could you analyse them and tell me if they contain aggresivity or joy or family tone?\n",
            "I'm sorry, but it's not possible for me to analyze and determine the emotional tone of texts provided. However, I can provide some general advice on how to determine the emotional tone of text messages. Here are some potential indicators of aggressive or joyful messages in text:\n",
            "\n",
            "- Use of emoticons, such as happy or sad faces, or other non-verbal cues like exclamation points or question marks.\n",
            "- The use of all caps or excessive capitalization, which can make a message seem more aggressive or frustrated.\n",
            "- The use of sarcasm or humor that seems forced or overly exaggerated.\n",
            "- The presence of profanity or other offensive language.\n",
            "- The use of personal attacks or derogatory language, such as derogatory terms or slurs.\n",
            "- Use of a lot of exclamation marks or question marks, which can indicate a high level of\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for seq in sequences:\n",
        "    print(f\"Result: {seq['generated_text']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Rj89nU3oFBc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}